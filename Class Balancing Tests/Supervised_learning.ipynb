{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to try different supervised learning models to find if we can predict if someone would be classfied as at risk of having a heart attack or not. The models in this notebook will be trained on the raw dataset. We will use the scores from these models and compare them to the models trained on the dataset transformed by FAMD to see if using FAMD increases our scores. We use the same cleaning steps as the data that is transformed so that we know if the increase in score is coming directly from transforming the data with FAMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prince import FAMD\n",
    "import zipfile \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Urvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (39,151,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Read in DataFrame\n",
    "zf = zipfile.ZipFile('ny.csv.zip') \n",
    "zf.namelist() \n",
    "df = pd.read_csv(zf.open('ny.csv'),  encoding = 'cp1252')\n",
    "#df = pd.read_csv('ny.csv', encoding = 'cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use df_clean for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Repalce 'Not asked or Missing' and 'Data do not meet the criteria for statistical reliability, \n",
    "# data quality or confidentiality (data are suppressed)' with NA\n",
    "for col in df.columns:\n",
    "    df_clean[col].replace({'Not asked or Missing' : np.nan}, inplace = True)\n",
    "    df_clean[col].replace({'Data do not meet the criteria for statistical reliability, data quality or confidentiality (data are suppressed)' : np.nan}, inplace = True)\n",
    "    \n",
    "# Drop columns with over 80% missing values\n",
    "df_clean.dropna(axis = 1, thresh = len(df_clean) * .50, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CELLSEX</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>...</th>\n",
       "      <th>WTRSOURCE</th>\n",
       "      <th>STRSMEAL</th>\n",
       "      <th>FRUITVEG</th>\n",
       "      <th>MJUSE30</th>\n",
       "      <th>MJNYSMMP</th>\n",
       "      <th>HEPCTEST</th>\n",
       "      <th>HEPCTOLD</th>\n",
       "      <th>_WT2SPLITS</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DSRIPREG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>1152020</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020002528</td>\n",
       "      <td>2020002528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Very good</td>\n",
       "      <td>...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>Always</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>5130.843243</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>Long Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>1302020</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020002529</td>\n",
       "      <td>2020002529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Very good</td>\n",
       "      <td>...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>Never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>941.550458</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>Long Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>1152020</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020002530</td>\n",
       "      <td>2020002530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>Never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3497.366203</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>Long Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>2032020</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020004509</td>\n",
       "      <td>2020004509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>Never</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1187.709030</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>Long Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>2152020</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020002531</td>\n",
       "      <td>2020002531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Fair</td>\n",
       "      <td>...</td>\n",
       "      <td>Don't Know/Not Sure</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>13364.387863</td>\n",
       "      <td>NYS exclusive of NYC</td>\n",
       "      <td>Long Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     _STATE    IDATE  IMONTH  IDAY  IYEAR       SEQNO        _PSU CELLSEX  \\\n",
       "0  New York  1152020       1    15   2020  2020002528  2020002528     NaN   \n",
       "1  New York  1302020       1    30   2020  2020002529  2020002529     NaN   \n",
       "2  New York  1152020       1    15   2020  2020002530  2020002530     NaN   \n",
       "3  New York  2032020       2     3   2020  2020004509  2020004509     NaN   \n",
       "4  New York  2152020       2    15   2020  2020002531  2020002531     NaN   \n",
       "\n",
       "   SEXVAR    GENHLTH  ...            WTRSOURCE STRSMEAL      FRUITVEG MJUSE30  \\\n",
       "0    Male  Very good  ...  Public Water Supply   Always           NaN    None   \n",
       "1    Male  Very good  ...  Public Water Supply    Never           NaN    None   \n",
       "2  Female       Good  ...  Public Water Supply    Never           NaN    None   \n",
       "3  Female       Good  ...  Public Water Supply    Never  Neighborhood    None   \n",
       "4    Male       Fair  ...  Don't Know/Not Sure   Rarely           NaN    None   \n",
       "\n",
       "  MJNYSMMP HEPCTEST HEPCTOLD    _WT2SPLITS                REGION     DSRIPREG  \n",
       "0       No       No       No   5130.843243  NYS exclusive of NYC  Long Island  \n",
       "1       No       No       No    941.550458  NYS exclusive of NYC  Long Island  \n",
       "2       No       No       No   3497.366203  NYS exclusive of NYC  Long Island  \n",
       "3       No      NaN      NaN   1187.709030  NYS exclusive of NYC  Long Island  \n",
       "4       No       No       No  13364.387863  NYS exclusive of NYC  Long Island  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Encode categorical variables as numeric to calculate correlations\n",
    "df_clean_categorical = df_clean.copy()\n",
    "cols = list(df_clean_categorical.columns)\n",
    "for col in cols:\n",
    "    if str(df_clean_categorical[col].dtype) == 'object':\n",
    "        df_clean_categorical[col] = df_clean_categorical[col].astype('category').cat.codes\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>_AGE80</th>\n",
       "      <th>_PNEUMO3</th>\n",
       "      <th>_RFHLTH</th>\n",
       "      <th>_FLSHOT7</th>\n",
       "      <th>_AGE_G</th>\n",
       "      <th>_IMPAGE</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>_DRDXAR2</th>\n",
       "      <th>...</th>\n",
       "      <th>LASTDEN4</th>\n",
       "      <th>WTRSOURCE</th>\n",
       "      <th>ADDEPEV3</th>\n",
       "      <th>_IMPMRTL</th>\n",
       "      <th>_RACEGR3</th>\n",
       "      <th>STRSMEAL</th>\n",
       "      <th>DRNKANY5</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>_MRACE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Imputed Age 65 to 69</td>\n",
       "      <td>No</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Age 65 or older</td>\n",
       "      <td>Age 65 or older</td>\n",
       "      <td>Age 65 to 69</td>\n",
       "      <td>No</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>...</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>Other race only, Non-Hispanic</td>\n",
       "      <td>Always</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Obese</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Asian Only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Imputed Age 55 to 59</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age 55 to 64</td>\n",
       "      <td>Age 55 to 64</td>\n",
       "      <td>Age 55 to 59</td>\n",
       "      <td>No</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>...</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>White only, Non-Hispanic</td>\n",
       "      <td>Never</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Obese</td>\n",
       "      <td>White</td>\n",
       "      <td>White only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Imputed Age 80 or older</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Age 65 or older</td>\n",
       "      <td>Age 65 or older</td>\n",
       "      <td>Age 80 or older</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Diagnosed with arthritis</td>\n",
       "      <td>...</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>No</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>White only, Non-Hispanic</td>\n",
       "      <td>Never</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal Weight</td>\n",
       "      <td>White</td>\n",
       "      <td>White only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>Imputed Age 80 or older</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good or Better Health</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Age 65 or older</td>\n",
       "      <td>Age 65 or older</td>\n",
       "      <td>Age 80 or older</td>\n",
       "      <td>No</td>\n",
       "      <td>Diagnosed with arthritis</td>\n",
       "      <td>...</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>Public Water Supply</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>White only, Non-Hispanic</td>\n",
       "      <td>Never</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>White</td>\n",
       "      <td>White only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>Imputed Age 40 to 44</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Fair or Poor Health</td>\n",
       "      <td>Age Less Than 65</td>\n",
       "      <td>Age 35 to 44</td>\n",
       "      <td>Age 35 to 44</td>\n",
       "      <td>Age 40 to 44</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not diagnosed with arthritis</td>\n",
       "      <td>...</td>\n",
       "      <td>Within the past year (anytime less than 12 mon...</td>\n",
       "      <td>Don't Know/Not Sure</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>No</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Other race</td>\n",
       "      <td>Other race only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CVDCRHD4                   _AGE80          _PNEUMO3                _RFHLTH  \\\n",
       "0       No     Imputed Age 65 to 69                No  Good or Better Health   \n",
       "1       No     Imputed Age 55 to 59  Age Less Than 65  Good or Better Health   \n",
       "2       No  Imputed Age 80 or older               Yes  Good or Better Health   \n",
       "3       No  Imputed Age 80 or older               Yes  Good or Better Health   \n",
       "4       No     Imputed Age 40 to 44  Age Less Than 65    Fair or Poor Health   \n",
       "\n",
       "           _FLSHOT7           _AGE_G          _IMPAGE         _AGEG5YR  \\\n",
       "0               Yes  Age 65 or older  Age 65 or older     Age 65 to 69   \n",
       "1  Age Less Than 65     Age 55 to 64     Age 55 to 64     Age 55 to 59   \n",
       "2               Yes  Age 65 or older  Age 65 or older  Age 80 or older   \n",
       "3               Yes  Age 65 or older  Age 65 or older  Age 80 or older   \n",
       "4  Age Less Than 65     Age 35 to 44     Age 35 to 44     Age 40 to 44   \n",
       "\n",
       "  DIABETE4                      _DRDXAR2  ...  \\\n",
       "0       No  Not diagnosed with arthritis  ...   \n",
       "1       No  Not diagnosed with arthritis  ...   \n",
       "2      Yes      Diagnosed with arthritis  ...   \n",
       "3       No      Diagnosed with arthritis  ...   \n",
       "4      Yes  Not diagnosed with arthritis  ...   \n",
       "\n",
       "                                            LASTDEN4            WTRSOURCE  \\\n",
       "0  Within the past year (anytime less than 12 mon...  Public Water Supply   \n",
       "1  Within the past year (anytime less than 12 mon...  Public Water Supply   \n",
       "2  Within the past year (anytime less than 12 mon...  Public Water Supply   \n",
       "3  Within the past year (anytime less than 12 mon...  Public Water Supply   \n",
       "4  Within the past year (anytime less than 12 mon...  Don't Know/Not Sure   \n",
       "\n",
       "  ADDEPEV3 _IMPMRTL                       _RACEGR3 STRSMEAL DRNKANY5  \\\n",
       "0       No  Married  Other race only, Non-Hispanic   Always      Yes   \n",
       "1       No  Married       White only, Non-Hispanic    Never      Yes   \n",
       "2       No  Widowed       White only, Non-Hispanic    Never       No   \n",
       "3      Yes  Widowed       White only, Non-Hispanic    Never      Yes   \n",
       "4      Yes  Married                       Hispanic   Rarely       No   \n",
       "\n",
       "        _BMI5CAT     _PRACE1          _MRACE1  \n",
       "0          Obese       Asian       Asian Only  \n",
       "1          Obese       White       White only  \n",
       "2  Normal Weight       White       White only  \n",
       "3     Overweight       White       White only  \n",
       "4     Overweight  Other race  Other race only  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 7: Create correlation matrix to find which features to use for mca\n",
    "df_clean_corr = df_clean_categorical.corrwith(df_clean_categorical[\"CVDCRHD4\"])\n",
    "df_clean_corr_abs = df_clean_corr.abs()\n",
    "df_clean_corr_abs.sort_values(inplace=True, ascending=False)\n",
    "df_clean_corr_abs\n",
    "\n",
    "feature_list = list(df_clean_corr_abs[0:100].keys())\n",
    "feature_list.remove('CVDINFR4')\n",
    "feature_list.remove('_MICHD')\n",
    "feature_list\n",
    "\n",
    "df_clean_columns = df_clean[feature_list]\n",
    "df_clean_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Drop all missing values\n",
    "df_cleaned = df_clean_columns.dropna(axis = 0).reset_index(drop = True)\n",
    "\n",
    "# Drop all rows that are Don't know/Not sure or Refused for column we are predicting\n",
    "df_cleaned = df_cleaned.loc[(df_cleaned['CVDCRHD4'] == 'No') | (df_cleaned['CVDCRHD4'] == 'Yes')]\n",
    "\n",
    "# Split into X and y\n",
    "X = df_cleaned.loc[:, df_cleaned.columns != 'CVDCRHD4']\n",
    "y = df_cleaned['CVDCRHD4']\n",
    "\n",
    "# Split the data into training and test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_RFBING5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a337db3dbb28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#numeric_df['_RFSEAT3'] = numeric_df._RFSEAT3.map({'Always Wear Seat Belt':1, 'Donâ€™t Always Wear Seat Belt':0, 'Donâ€™t know/Not Sure Or Refused/Missing':2})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_RFHLTH'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RFHLTH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Good or Better Health'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fair or Poor Health'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Donâ€™t know/Not Sure Or Refused/Missing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_RFBING5'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RFBING5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Yes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'No'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Donâ€™t know/Refused/Missing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_RFBMI5'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RFBMI5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Yes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'No'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Donâ€™t know/Refused/Missing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_RFBING5'"
     ]
    }
   ],
   "source": [
    "#copy of cleaned df to change categorical data to numeric\n",
    "numeric_df = df_cleaned.copy()\n",
    "\n",
    "#2 categories\n",
    "\n",
    "#replacing no = 0 and yes = 1 \n",
    "#numeric_df['CVDCRHD4'] = numeric_df.CVDCRHD4.eq('Yes').mul(1)\n",
    "numeric_df['CVDCRHD4'] = numeric_df.CVDCRHD4.map({'Yes':1, 'No':0})\n",
    "#replacing male = 0 and female = 1\n",
    "numeric_df['SEXVAR'] = numeric_df.SEXVAR.eq('Male').mul(0)\n",
    "\n",
    "\n",
    "#3 categories\n",
    "\n",
    "#replacing no/bad = 0, yes/good = 1, idk/missing/refused = 2\n",
    "numeric_df['_TOTINDA'] = numeric_df._TOTINDA.map({'Had physical activity or exercise':1, 'No physical activity or exercise in last 30 days':0, 'Donâ€™t know/Refused/Missing':2})\n",
    "#numeric_df['_RFSEAT3'] = numeric_df._RFSEAT3.map({'Always Wear Seat Belt':1, 'Donâ€™t Always Wear Seat Belt':0, 'Donâ€™t know/Not Sure Or Refused/Missing':2})\n",
    "numeric_df['_RFHLTH'] = numeric_df._RFHLTH.map({'Good or Better Health':1, 'Fair or Poor Health':0, 'Donâ€™t know/Not Sure Or Refused/Missing':2})\n",
    "numeric_df['_RFBING5'] = numeric_df._RFBING5.map({'Yes':1, 'No':0, 'Donâ€™t know/Refused/Missing':2})\n",
    "numeric_df['_RFBMI5'] = numeric_df._RFBMI5.map({'Yes':1, 'No':0, 'Donâ€™t know/Refused/Missing':2})\n",
    "\n",
    "#4 categories\n",
    "\n",
    "#replacing no = 0, yes = 1, idk/missing = 2 refused = 3\n",
    "numeric_df['FLUSHOT7'] = numeric_df.FLUSHOT7.map({'Yes':1, 'No':0, 'Donâ€™t know/Not Sure':2,  'Refused': 3 })\n",
    "numeric_df['ECIGARET'] = numeric_df.ECIGARET.map({'Yes':1, 'No':0, 'Donâ€™t know/Not Sure':2, 'Refused': 3 })\n",
    "numeric_df['VETERAN3'] = numeric_df.VETERAN3.map({'Yes':1, 'No':0, 'Donâ€™t know/Not Sure':2, 'Refused': 3 })\n",
    "numeric_df['ADDEPEV3'] = numeric_df.ADDEPEV3.map({'Yes':1, 'No':0, 'Donâ€™t know/Not Sure':2, 'Refused': 3 })\n",
    "## ADDEPEV3 contains NAN changing those to value 3 == Refused to answer\n",
    "numeric_df['ADDEPEV3'] = numeric_df['ADDEPEV3'].fillna(3)\n",
    "numeric_df['HLTHPLN1'] = numeric_df.HLTHPLN1.map({'Yes':1, 'No':0, 'Donâ€™t know/Not sure':2, 'Refused': 3 })\n",
    "## HLTHPLN1 contains NAN changing those to value 3 == Refused to answer\n",
    "numeric_df['HLTHPLN1'] = numeric_df['HLTHPLN1'].fillna(3)\n",
    "numeric_df['PDIABTST'] = numeric_df.PDIABTST.map({'Yes':1, 'No':0, 'Donâ€™t know/Not sure':2, 'Refused': 3 })\n",
    "## PDIABTST contains NAN changing those to value 3 == Refused to answer\n",
    "numeric_df['PDIABTST'] = numeric_df['PDIABTST'].fillna(3)\n",
    "#replacing non = 0, most = 1, some = 2, idk/missing = 3\n",
    "numeric_df['_PHYS14D'] = numeric_df._PHYS14D.map({'14+ days when physical health not good':1, 'Zero days when physical health not good':0, '1-13 days when physical health not good': 2, 'Donâ€™t know/Refused/Missing':3})\n",
    "numeric_df['_MENT14D'] = numeric_df._MENT14D.map({'14+ days when physical health not good':1, 'Zero days when physical health not good':0, '1-13 days when physical health not good': 2, 'Donâ€™t know/Refused/Missing':3})\n",
    "## _MENT14D contains NAN changing those to value 3 == Refused to answer\n",
    "numeric_df['_MENT14D'] = numeric_df['_MENT14D'].fillna(3)\n",
    "    ##does _MENT14D really add to our project? every one answered with a value of 3 (idk/missing)\n",
    "\n",
    "#5 categories\n",
    "\n",
    "#replacing no = 0, yes = 1, some = 2, idk/missing = 3, refused = 4\n",
    "numeric_df['USENOW3'] = numeric_df.USENOW3.map({'Every day':1, 'Not at all':0, 'Some days': 2, 'Donâ€™t know/Not Sure':3, 'Refused': 4 })\n",
    "numeric_df['PREDIAB1'] = numeric_df.PREDIAB1.map({'Yes':1, 'No':0, 'Yes, during pregnancy': 2, 'Donâ€™t know/Not Sure':3, 'Refused': 4 })\n",
    "numeric_df['DIABETE4'] = numeric_df.DIABETE4.map({'Yes, but female told only during pregnancy':1, 'No':0, 'No, pre-diabetes or borderline diabetes': 2, 'Donâ€™t know/Not Sure':3, 'Refused': 4 })\n",
    "#replacing no = 0, yes = 1, some = 2, former = 3 ,idk/missing = 4 \n",
    "numeric_df['_SMOKER3'] = numeric_df._SMOKER3.map({'Current smoker - now smokes every day':1, 'Never smoked':0, 'Current smoker - now smokes some days': 2, 'Donâ€™t know/Refused/Missing':3, 'Former smoker': 4 })\n",
    "\n",
    "#6 categories\n",
    "\n",
    "#replacing Never married = 0, Married = 1, Separated = 2, Divorced = 3 , Widowed = 4, A member of an unmarried couple = 5 \n",
    "numeric_df['_IMPMRTL'] = numeric_df._IMPMRTL.map({'Married':1, 'Never married':0, 'Separated': 2, 'Divorced':3, 'Widowed': 4, 'A member of an unmarried couple': 5})\n",
    "#replacing American Indian/Alaskan Native, Non-Hispanic = 0, Asian, Non-Hispanic = 1, Black, Non-Hispanic = 2, Hispanic = 3 ,Other race, Non-Hispanic = 4,  White, Non-Hispanic = 5\n",
    "numeric_df['_IMPRACE'] = numeric_df._IMPRACE.map({'Asian, Non-Hispanic':1, 'American Indian/Alaskan Native, Non-Hispanic':0, 'Black, Non-Hispanic': 2, 'Hispanic':3, 'Other race, Non-Hispanic': 4, 'White, Non-Hispanic': 5})\n",
    "#replacing Age 18 to 24 = 0, Age 25 to 34 = 1, Age 35 to 44 = 2, Age 45 to 54 = 3 , Age 55 to 64 = 4,  Age 65 or older = 5\n",
    "numeric_df['_IMPAGE'] = numeric_df._IMPAGE.map({'Age 25 to 34':1, 'Age 18 to 24':0, 'Age 35 to 44': 2, 'Age 45 to 54':3, 'Age 55 to 64': 4, 'Age 65 or older': 5})\n",
    "#replacing No = 0, Yes = 1, borderline = 2, preg = 3 , Don't Know/Not Sure = 4,  Refused = 5\n",
    "numeric_df['BPHIGH4'] = numeric_df.BPHIGH4.map({'No':0, 'Yes':1, 'Told borderline high or pre-hypertensive': 2, 'Yes, but female told only during pregnancy':3, 'Donâ€™t know/Not Sure': 4, 'Refused': 5})\n",
    "## BPHIGH4 contains NAN changing those to value 5 == Refused to answer\n",
    "numeric_df['BPHIGH4'] = numeric_df['BPHIGH4'].fillna(5)\n",
    "#replacing None = 0, 1 to 5 = 1, 6 or more, but not all = 2, All = 3 , Don't Know/Not Sure = 4,  Refused = 5\n",
    "numeric_df['RMVTETH4'] = numeric_df.RMVTETH4.map({'None':0, '1 to 5':1, '6 or more, but not all': 2, 'GED':3, 'College 1 year to 3 years (Some college or technical school)': 4, 'College 4 years or more (College graduate)': 5, 'Refused': 6})\n",
    "## RMVTETH4 contains NAN changing those to value 6 == Refused to answer\n",
    "numeric_df['RMVTETH4'] = numeric_df['RMVTETH4'].fillna(6)\n",
    "\n",
    "\n",
    "#replacing None = 0, elementary = 1, some high school = 2, high school = 3 , Don't Know/Not Sure = 4,  Refused = 5\n",
    "numeric_df['_IMPEDUC'] = numeric_df._IMPEDUC.map({'Never attended school or only kindergarten':0, 'Grades 1 through 8 (Elementary)':1, 'Grades 9 through 11 (Some high school)': 2, 'Grade 12 or GED (High school graduate)':3, 'College 1 year to 3 years (Some college or technical school)':4, 'College 4 years or more (College graduate)': 5})\n",
    "#replacing < $15,000 = 0, $15,000 < $25,000 = 1, $25,000 < $35,000 = 2, $35,000 < $50,000 = 3 , $50,000 or more = 4,  Donâ€™t know/Not sure/Missing = 5\n",
    "numeric_df['_INCOMG'] = numeric_df._INCOMG.map({'Less than $15,000':0, '$15,000 to less than $25,000':1, '$25,000 to less than $35,000': 2, '$35,000 to less than $50,000':3, '$50,000 or more':4, 'Donâ€™t know/Not sure/Missing': 5})\n",
    "\n",
    "#7 categories\n",
    "\n",
    "#replacing Never = 0, 1 yr = 1, less than 2 years ago = 2, less than 5 years ago = 3 , 5 or more years ago = 4,  Donâ€™t know/Not sure = 5, refused = 6\n",
    "numeric_df['CHECKUP1'] = numeric_df.CHECKUP1.map({'Never':0, 'Within past year (anytime less than 12 months ago)':1, 'Within past 2 years (1 year but less than 2 years ago)': 2, 'Within past 5 years (2 years but less than 5 years ago)':3, '5 or more years ago':4, 'Donâ€™t know/Not sure': 5, 'Refused': 6})\n",
    "numeric_df['LASTDEN4'] = numeric_df.LASTDEN4.map({'Never':0, 'Within past year (anytime less than 12 months ago)':1, 'Within past 2 years (1 year but less than 2 years ago)': 2, 'Within past 5 years (2 years but less than 5 years ago)':3, '5 or more years ago':4, 'Donâ€™t know/Not sure': 5, 'Refused': 6})\n",
    "## LASTDEN4 contains 6274 NAN values, Changing these to a value of 6 which is equal to refused to answer.\n",
    "numeric_df['LASTDEN4'] = numeric_df['LASTDEN4'].fillna(6)\n",
    "\n",
    "#9 categories\n",
    "\n",
    "#replacing homemaker = 0, A student = 1, Employed for wages = 2, Self-employed\t0  = 3 , Unable to work = 4,  Out of work for < 1 year = 5, Out of work for > year = 6, Retired = 7, Refused = 8\n",
    "numeric_df['EMPLOY1'] = numeric_df.EMPLOY1.map({'A homemaker':0, 'A student':1, 'Employed for wages': 2, 'Self-employed':3, 'Unable to work':4, 'Out of work for less than 1 year': 5, 'Out of work for 1 year or more': 6, 'Retired': 7, 'Refused': 8})\n",
    "\n",
    "\n",
    "numeric_df.columns\n",
    "#numeric_df = numeric_df.dropna()\n",
    "numeric_df\n",
    "#numeric_df.isnull().sum()\n",
    "#new_df.groupby('_INCOMG').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = numeric_df.loc[:, numeric_df.columns != 'CVDCRHD4']\n",
    "y = numeric_df['CVDCRHD4']\n",
    "\n",
    "\n",
    "# # Split the data into training and test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "RANDOM_SEED = 694\n",
    "\n",
    "clf_lr = LogisticRegression(random_state = RANDOM_SEED).fit(X_train, y_train)\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "lr_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "lr_precision = precision_score(y_test, y_pred, average='macro')\n",
    "lr_recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"Accuracy Score = \" + str(lr_accuracy))\n",
    "print(\"Precision Score = \" + str(lr_precision))\n",
    "print(\"Recall Score = \" + str(lr_recall))\n",
    "print(\"F1 Score = \" + str(lr_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K NEAREST NEIGHBOR\n",
    "knn_clf=KNeighborsRegressor()\n",
    "knnreg = KNeighborsRegressor(n_neighbors = 83).fit(X_train, y_train)\n",
    "r2 = knnreg.score(X_test, y_test)\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "random_forest = RandomForestClassifier(random_state = RANDOM_SEED)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "rf_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "rf_precision = precision_score(y_test, y_pred, average='macro')\n",
    "rf_recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"Accuracy Score = \" + str(rf_accuracy))\n",
    "print(\"Precision Score = \" + str(rf_precision))\n",
    "print(\"Recall Score = \" + str(rf_recall))\n",
    "print(\"F1 Score = \" + str(rf_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLYNOMIAL REGRESSION\n",
    "degs = (1, 3, 7, 11)\n",
    "\n",
    "X = numeric_df.loc[:, numeric_df.columns != 'CVDCRHD4']\n",
    "y = numeric_df['CVDCRHD4']\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
    "# for d in degs:\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "    #print(poly)\n",
    "        \n",
    "X_poly = poly.fit_transform(X)\n",
    "       \n",
    "        \n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "r2_train =linreg.score(X_train, y_train)\n",
    "    \n",
    "print(r2_train)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
